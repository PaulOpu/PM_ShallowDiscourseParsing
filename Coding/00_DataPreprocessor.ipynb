{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataPreprocessor\n",
    "\n",
    "This notebook prepares the input data for our project. We received the sense predictions for each parser of the ConLL challenge of 2016 from Te Rutherford (special thanks to him). Unfortunately, the arg1 and arg2 spans of all parsers are the same, so we had to randomize them to generate a \"real\" parser output. Therefore, we changed in some of the predicted relations connectives, types, arg1 or/and arg2 spans. Moreover, we added additional attributes that identifies the changes and parser names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "from read_write_files import read_json,save_json,get_parser_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_compare_attr(relation,parser_name=\"None\"):\n",
    "    # To compare each parser, we add new attributes to the relation dictionaries\n",
    "\n",
    "    # param relation   Relation of the parser\n",
    "    # param parser_name Name of the Parser\n",
    "    \n",
    "    # return Relation with Connective RawText if not present, \n",
    "    # \"Change\" (if we create a randomized relation we can track which changes were made to the relation) \n",
    "    # and \"Parser\" (parser_name) attribute\n",
    "    \n",
    "    new_rel = relation.copy()\n",
    "    conn = new_rel[\"Connective\"]\n",
    "    if not conn.has_key(\"RawText\"):\n",
    "        new_rel[\"Connective\"][\"RawText\"] = \"\"\n",
    "        \n",
    "    new_rel[\"Change\"] = \"None\"\n",
    "    new_rel[\"Parser\"] = parser_name\n",
    "    \n",
    "    return new_rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessor:\n",
    "    # Class for preprocessing the relations e.g by adding additional attributes or randomize relations to \n",
    "    # create simulated parser outputs (because we only had access to the parser outputs for the sense challenge)\n",
    "    \n",
    "    \n",
    "    def __init__(self,parsers,gold_path):\n",
    "        \n",
    "        self.parser_preds = []\n",
    "        for name,path in parsers:\n",
    "            self.parser_preds += [{\n",
    "                \"parser\":name,\n",
    "                \"relations\": [add_compare_attr(rel,parser_name=name) for rel in read_json(path)]\n",
    "            }]\n",
    "        \n",
    "        self.gold_rel = [add_compare_attr(rel,parser_name=\"Gold\") for rel in read_json(gold_path)]\n",
    "        self.get_unique_attr(self.gold_rel)\n",
    "    \n",
    "    \n",
    "    def get_unique_attr(self,relations):\n",
    "        # Get the unique values for connectives, parser_names and types of relations\n",
    "\n",
    "        # param relations   Relations of the parser\n",
    "        \n",
    "        # return class variables with the unique values\n",
    "        \n",
    "        self.unique_connect = set()\n",
    "        self.unique_sense = set()\n",
    "        self.unique_type = set()\n",
    "        \n",
    "        for rel_dic in relations:\n",
    "            self.unique_connect.update([rel_dic[\"Connective\"][\"RawText\"]])\n",
    "            self.unique_sense.update(rel_dic[\"Sense\"])\n",
    "            self.unique_type.update([rel_dic[\"Type\"]])\n",
    "            \n",
    "        self.unique_connect = self.unique_connect.difference([\"\"])\n",
    "        \n",
    "    def randomize_rel(self,relation,change):\n",
    "        # Change a specific value of the relation \n",
    "\n",
    "        # param relation   Relation of a parser\n",
    "        # param change   which attribute should be changed\n",
    "        \n",
    "        # return relation with one changed attribute\n",
    "        relation[\"Change\"] = change\n",
    "        \n",
    "        if change == \"Arg1\" or change == \"Arg2\":\n",
    "            numb_add_tok = random.randint(0,10)\n",
    "            last_tok = relation[change][\"TokenList\"][-1]\n",
    "            add_tok = [i for i in range(last_tok+1,last_tok+numb_add_tok)]\n",
    "            relation[change][\"TokenList\"] += add_tok\n",
    "        elif change == \"Args\":\n",
    "            relation = self.randomize_rel(relation,\"Arg1\")\n",
    "            relation = self.randomize_rel(relation,\"Arg2\")\n",
    "        elif change == \"Type\":\n",
    "            if relation[change] == \"Explicit\":\n",
    "                types = self.unique_type.copy()\n",
    "                types = types.difference([\"Explicit\"])\n",
    "                relation[change] = random.sample(types,1)[0]\n",
    "                relation[\"Connective\"][\"RawText\"] = \"\"\n",
    "                relation[\"Connective\"][\"TokenList\"] = []\n",
    "            else:\n",
    "                types = self.unique_type.copy()\n",
    "                types = types.difference([\"Explicit\"])\n",
    "                relation[change] = random.sample(types,1)[0]\n",
    "                if relation[change] == \"Explicit\":\n",
    "                    relation = self.change_connective(relation)\n",
    "                        \n",
    "        elif change == \"Connective\":\n",
    "            relation = self.change_connective(relation)\n",
    "        \n",
    "        return relation\n",
    "    \n",
    "    def change_connective(self,relation):\n",
    "        arg1 = relation[\"Arg1\"][\"TokenList\"]\n",
    "        arg2 = relation[\"Arg2\"][\"TokenList\"]\n",
    "        args = arg1+arg2\n",
    "        relation[\"Connective\"][\"RawText\"] = random.sample(self.unique_connect,1)[0]\n",
    "        relation[\"Connective\"][\"TokenList\"] = [random.randint(min(args),max(args))]\n",
    "        \n",
    "        return relation\n",
    "    \n",
    "    def create_randomized_parser_output(self,parser_name):\n",
    "        # Create a randomized parser output, that should behave like a real parser prediction\n",
    "\n",
    "        # param parser_name   name of a parser\n",
    "        \n",
    "        # return class variables with the unique values\n",
    "        parser_rel = [\n",
    "            parser_pred[\"relations\"] \n",
    "            for parser_pred in self.parser_preds \n",
    "            if parser_pred[\"parser\"] == parser_name][0]\n",
    "        \n",
    "        select_len = int(len(parser_rel)*(random.randrange(80,100,5))/100)\n",
    "        selected_rel = random.sample(parser_rel,select_len)[:]\n",
    "            \n",
    "        \n",
    "        change_len = int(select_len*0.6)\n",
    "        change_rel_ind = random.sample(range(change_len),change_len)\n",
    "        \n",
    "        changes = [\"Arg1\",\"Arg2\",\"Args\",\"Type\",\"Connective\"] \n",
    "        for ind,rel in enumerate(selected_rel):\n",
    "            if ind in change_rel_ind:\n",
    "                change = random.sample(changes,1)[0]\n",
    "                rel = self.randomize_rel(rel,change)\n",
    "                \n",
    "        return selected_rel\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test of Randomization\n",
    "\n",
    "This shows the process of radnomization, which we use to generate real parser outputs due to the absence of real data for arg1/arg2 and connectives. Nevertheless, the senses are originally from the conll2016 challenge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Arg2TokenList': [42, 43, 44, 45, 46, 47, 48, 49, 50, 51], 'DocID': u'wikinews_101184', 'Parser': 'Pred', 'Connective': {u'RawText': '', u'TokenList': []}, 'Arg1TokenList': [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40], 'Sense': [u'Temporal.Asynchronous.Succession'], 'Type': u'Explicit'}\n",
      "Connective\n",
      "Connective\n",
      "{'Arg2TokenList': [42, 43, 44, 45, 46, 47, 48, 49, 50, 51], 'Arg1TokenList': [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40], 'DocID': u'wikinews_101184', 'Sense': [u'Temporal.Asynchronous.Succession'], 'Parser': 'Pred', 'Type': u'Explicit', 'Connective': {u'RawText': u'As', u'TokenList': [36]}}\n"
     ]
    }
   ],
   "source": [
    "changes = [\"Arg1\",\"Arg2\",\"Args\",\"Type\",\"Connective\"] \n",
    "changes = [\"Type\",\"Connective\"] \n",
    "change = random.sample(changes,1)[0]\n",
    "print(preprocessor.parser_rel[0])\n",
    "print(change)\n",
    "after = randomizer.randomize_rel(randomizer.parser_rel[0].copy(),change)\n",
    "print(after)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save (randomized) Training Sets\n",
    "\n",
    "We tokk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_path = \"data/gold_standard/test/relations.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/submissions/sense_only/test/\"\n",
    "parsers = get_parser_paths(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = Preprocessor(parsers,gold_path)\n",
    "for name,pars_path in parsers: \n",
    "    rels = preprocessor.create_randomized_parser_output(name)\n",
    "    save_json(rels,\"data/submissions/randomized/test/\"+name+\".json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_parser_rel(preprocessor.gold_rel,\"data/gold_standard/test/gold.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_test_path = \"data/gold_standard/blind/relations.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/submissions/sense_only/blind/\"\n",
    "parsers = get_parser_paths(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = Preprocessor(parsers,gold_test_path)\n",
    "for name,pars_path in parsers: \n",
    "    rels = preprocessor.create_randomized_parser_output(name)\n",
    "    save_json(rels,\"data/submissions/randomized/blind/\"+name+\".json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_json(preprocessor.gold_rel,\"data/gold_standard/blind/gold.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
