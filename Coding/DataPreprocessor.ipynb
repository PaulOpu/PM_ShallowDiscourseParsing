{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataPreprocessor\n",
    "\n",
    "This notebook takes the original files and add some attributes for a comparison later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "from read_write_files import read_json,save_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'DEPRECATED'\n",
    "def create_comparison_format1(relation,gold=True):\n",
    "    conn = dict(relation[\"Connective\"])\n",
    "    if conn.has_key(\"CharacterSpanList\"):\n",
    "        del conn[\"CharacterSpanList\"]\n",
    "    if not conn.has_key(\"RawText\"):\n",
    "        conn[\"RawText\"] = \"\"\n",
    "\n",
    "    dic = {\n",
    "        \"DocID\": relation[\"DocID\"],\n",
    "        \"Sense\": relation[\"Sense\"],\n",
    "        \"Type\" : relation[\"Type\"],\n",
    "        \"Connective\": conn,\n",
    "        \"Change\": \"None\"\n",
    "    }\n",
    "\n",
    "    if gold:\n",
    "        dic[\"Arg1TokenList\"] = [token[2] for token in relation[\"Arg1\"][\"TokenList\"]]\n",
    "        dic[\"Arg2TokenList\"] = [token[2] for token in relation[\"Arg2\"][\"TokenList\"]]\n",
    "        dic[\"Parser\"] = \"Gold\"\n",
    "    else:\n",
    "        dic[\"Arg1TokenList\"] = relation[\"Arg1\"][\"TokenList\"]\n",
    "        dic[\"Arg2TokenList\"] = relation[\"Arg2\"][\"TokenList\"]\n",
    "        dic[\"Parser\"] = \"Pred\"\n",
    "\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_compare_attr(relation,parser_name=\"None\"):\n",
    "    new_rel = relation.copy()\n",
    "    conn = new_rel[\"Connective\"]\n",
    "    if not conn.has_key(\"RawText\"):\n",
    "        new_rel[\"Connective\"][\"RawText\"] = \"\"\n",
    "        \n",
    "    new_rel[\"Change\"] = \"None\"\n",
    "    new_rel[\"Parser\"] = parser_name\n",
    "    \n",
    "    return new_rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessor:\n",
    "    \n",
    "    def __init__(self,parsers,gold_path):\n",
    "        \n",
    "        self.parser_preds = []\n",
    "        for name,path in parsers:\n",
    "            self.parser_preds += [{\n",
    "                \"parser\":name,\n",
    "                \"relations\": [add_compare_attr(rel,parser_name=name) for rel in read_json(path)]\n",
    "            }]\n",
    "        \n",
    "        #self.parser_rel = [add_compare_attr(rel,parser_name=parser_name) for rel in read_parser_rel(parser_path)]\n",
    "        self.gold_rel = [add_compare_attr(rel,parser_name=\"Gold\") for rel in read_parser_rel(gold_path)]\n",
    "        self.get_unique_attr(self.gold_rel)\n",
    "    \n",
    "    \n",
    "    def get_unique_attr(self,relations):\n",
    "        self.unique_connect = set()\n",
    "        self.unique_sense = set()\n",
    "        self.unique_type = set()\n",
    "        \n",
    "        for rel_dic in relations:\n",
    "            self.unique_connect.update([rel_dic[\"Connective\"][\"RawText\"]])\n",
    "            self.unique_sense.update(rel_dic[\"Sense\"])\n",
    "            self.unique_type.update([rel_dic[\"Type\"]])\n",
    "            \n",
    "        self.unique_connect = self.unique_connect.difference([\"\"])\n",
    "        \n",
    "    def randomize_rel(self,relation,change):\n",
    "        relation[\"Change\"] = change\n",
    "        \n",
    "        if change == \"Arg1\" or change == \"Arg2\":\n",
    "            numb_add_tok = random.randint(0,10)\n",
    "            last_tok = relation[change][\"TokenList\"][-1]\n",
    "            add_tok = [i for i in range(last_tok+1,last_tok+numb_add_tok)]\n",
    "            relation[change][\"TokenList\"] += add_tok\n",
    "        elif change == \"Args\":\n",
    "            relation = self.randomize_rel(relation,\"Arg1\")\n",
    "            relation = self.randomize_rel(relation,\"Arg2\")\n",
    "        elif change == \"Type\":\n",
    "            if relation[change] == \"Explicit\":\n",
    "                types = self.unique_type.copy()\n",
    "                types = types.difference([\"Explicit\"])\n",
    "                relation[change] = random.sample(types,1)[0]\n",
    "                relation[\"Connective\"][\"RawText\"] = \"\"\n",
    "                relation[\"Connective\"][\"TokenList\"] = []\n",
    "            else:\n",
    "                types = self.unique_type.copy()\n",
    "                types = types.difference([\"Explicit\"])\n",
    "                relation[change] = random.sample(types,1)[0]\n",
    "                if relation[change] == \"Explicit\":\n",
    "                    relation = self.change_connective(relation)\n",
    "                        \n",
    "        elif change == \"Connective\":\n",
    "            relation = self.change_connective(relation)\n",
    "        \n",
    "        return relation\n",
    "    \n",
    "    def change_connective(self,relation):\n",
    "        arg1 = relation[\"Arg1\"][\"TokenList\"]\n",
    "        arg2 = relation[\"Arg2\"][\"TokenList\"]\n",
    "        args = arg1+arg2\n",
    "        relation[\"Connective\"][\"RawText\"] = random.sample(self.unique_connect,1)[0]\n",
    "        relation[\"Connective\"][\"TokenList\"] = [random.randint(min(args),max(args))]\n",
    "        \n",
    "        return relation\n",
    "    \n",
    "    def create_randomized_parser_output(self,parser_name):\n",
    "        \n",
    "        parser_rel = [\n",
    "            parser_pred[\"relations\"] \n",
    "            for parser_pred in self.parser_preds \n",
    "            if parser_pred[\"parser\"] == parser_name][0]\n",
    "        \n",
    "        select_len = int(len(parser_rel)*(random.randrange(80,100,5))/100)\n",
    "        selected_rel = random.sample(parser_rel,select_len)[:]\n",
    "            \n",
    "        \n",
    "        change_len = int(select_len*0.6)\n",
    "        change_rel_ind = random.sample(range(change_len),change_len)\n",
    "        \n",
    "        changes = [\"Arg1\",\"Arg2\",\"Args\",\"Type\",\"Connective\"] \n",
    "        for ind,rel in enumerate(selected_rel):\n",
    "            if ind in change_rel_ind:\n",
    "                change = random.sample(changes,1)[0]\n",
    "                rel = self.randomize_rel(rel,change)\n",
    "                \n",
    "        return selected_rel\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Arg2TokenList': [42, 43, 44, 45, 46, 47, 48, 49, 50, 51], 'DocID': u'wikinews_101184', 'Parser': 'Pred', 'Connective': {u'RawText': '', u'TokenList': []}, 'Arg1TokenList': [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40], 'Sense': [u'Temporal.Asynchronous.Succession'], 'Type': u'Explicit'}\n",
      "Connective\n",
      "Connective\n",
      "{'Arg2TokenList': [42, 43, 44, 45, 46, 47, 48, 49, 50, 51], 'Arg1TokenList': [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40], 'DocID': u'wikinews_101184', 'Sense': [u'Temporal.Asynchronous.Succession'], 'Parser': 'Pred', 'Type': u'Explicit', 'Connective': {u'RawText': u'As', u'TokenList': [36]}}\n"
     ]
    }
   ],
   "source": [
    "changes = [\"Arg1\",\"Arg2\",\"Args\",\"Type\",\"Connective\"] \n",
    "changes = [\"Type\",\"Connective\"] \n",
    "change = random.sample(changes,1)[0]\n",
    "print(preprocessor.parser_rel[0])\n",
    "print(change)\n",
    "after = randomizer.randomize_rel(randomizer.parser_rel[0].copy(),change)\n",
    "print(after)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save randomized changed Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_path = \"data/gold_standard/conll16st-en-03-29-16-blind-test/relations.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsers = [\n",
    "    (\"oslopots\",\"data/submissions/sense_only/blind/oslopots/output/output.json\"),\n",
    "    (\"nguyenlab\",\"data/submissions/sense_only/blind/nguyenlab/output/output.json\"),\n",
    "    (\"steven\",\"data/submissions/sense_only/blind/steven/output/output.json\")\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = Preprocessor(parsers,gold_path)\n",
    "for name,pars_path in parsers: \n",
    "    rels = preprocessor.create_randomized_parser_output(name)\n",
    "    save_parser_rel(rels,\"data/submissions/randomized/\"+name+\".json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_parser_rel(preprocessor.gold_rel,\"data/gold_standard/blind/gold.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Test Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_test_path = \"data/gold_standard/conll16st-en-03-29-16-dev/relations.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsers = [\n",
    "    (\"oslopots\",\"data/submissions/sense_only/dev/oslopots/output/output.json\"),\n",
    "    (\"nguyenlab\",\"data/submissions/sense_only/dev/nguyenlab/output/output.json\"),\n",
    "    (\"steven\",\"data/submissions/sense_only/dev/steven/output/output.json\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = Preprocessor(parsers,gold_test_path)\n",
    "for name,pars_path in parsers: \n",
    "    rels = preprocessor.create_randomized_parser_output(name)\n",
    "    save_parser_rel(rels,\"data/submissions/randomized/dev/\"+name+\".json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_json(preprocessor.gold_rel,\"data/gold_standard/dev/gold.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
