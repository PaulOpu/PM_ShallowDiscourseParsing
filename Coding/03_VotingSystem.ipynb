{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting Systems\n",
    "\n",
    "In this notebook we compare different voting systems to get the final prediction. Our models were trained on the blind test data, that is not biased by the training process and use the dev-test data to test our model.\n",
    "\n",
    "## Load Test Data and Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from read_write_files import read_json,save_json,get_parser_paths\n",
    "from helper_functions import get_sense_lists,align_parsers_to_gold,plot_confusion_matrix\n",
    "import numpy as np\n",
    "import conll16st.scorer as scorer\n",
    "import conll16st.partial_scorer as partial_scorer\n",
    "import random\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sense_model_path = \"data/project_files/test/sense_model.json\"\n",
    "total_alignment_path = \"data/project_files/blind/total_alignment.json\"\n",
    "test_data_path = \"data/gold_standard/blind/relations.json\"\n",
    "example_parser_path = \"data/submissions/sense_only/blind/oslopots/output/output.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_alignments = read_json(total_alignment_path)\n",
    "sense_model = read_json(sense_model_path)\n",
    "test_data = read_json(test_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_parser = read_json(example_parser_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_senses,parser_senses,parser_names = get_sense_lists(total_alignments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting Systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def voting(parser_preds,parser_names,model,voting_algorithm):\n",
    "    new_senses = []\n",
    "    \n",
    "    parser_pred_zip = zip(*parser_preds)\n",
    "    for predictions in parser_pred_zip:\n",
    "        result = voting_algorithm(predictions,model)\n",
    "        new_senses += [result]\n",
    "        \n",
    "    return new_senses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_wins_voting(predictions,model):\n",
    "    probs = []\n",
    "    sense_predictions = []\n",
    "    for ind,pred in enumerate(predictions):\n",
    "        sense_predictions += [pred]\n",
    "        sense_dic = model[ind][\"sense_pred\"]\n",
    "        if (pred == \"None\") or not (sense_dic.has_key(pred)):\n",
    "            probs += [0]\n",
    "        else:\n",
    "            probs += [sense_dic[pred][\"f1\"]]\n",
    "            \n",
    "    result = np.argmax(probs)\n",
    "    \n",
    "    if sum(probs) == 0:\n",
    "        result = -1\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_agreement(predictions,model):\n",
    "    sense_counter = Counter(predictions)\n",
    "    best_sense = sense_counter.most_common(1)[0][0]\n",
    "    \n",
    "    if best_sense == \"None\":\n",
    "        return -1\n",
    "    \n",
    "    return predictions.index(best_sense) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_wins_parsers = voting(parser_senses,parser_names,sense_model,best_wins_voting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_agreement_parsers = voting(parser_senses,parser_names,sense_model,max_agreement)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exchange new Attributes in Relation File\n",
    "\n",
    "Only for sense evaluation, because we take the arg span from the gold file to have a clear mapping between the gold and the prediction (only sense is exchanged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exchange_sense_values(parser_rel,alignment_list,best_relation_indexes):\n",
    "    relation_senses = {}\n",
    "    \n",
    "    for best_parser,alignments in zip(*[best_relation_indexes,alignment_list]):\n",
    "        if best_parser != -1:\n",
    "            best_sense = alignments[\"parsers\"][best_parser][\"Sense\"]\n",
    "            \n",
    "            relation_senses[alignments[\"gold\"][\"ID\"]] = best_sense\n",
    "            \n",
    "            #best_sense = best_parser_result[\"Sense\"][0]\n",
    "            #new_rel = alignments[\"gold\"].copy()\n",
    "            #new_rel[\"Sense\"] = best_sense\n",
    "    \n",
    "    \n",
    "    for rel in parser_rel:\n",
    "        rel_id = rel[\"ID\"]\n",
    "        if rel_id in relation_senses:\n",
    "            rel[\"Sense\"] = relation_senses[rel_id] \n",
    "        \n",
    "    return parser_rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_wins_relations = exchange_sense_values(example_parser,total_alignments,best_wins_parsers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_agreement_relations = exchange_sense_values(example_parser,total_alignments,max_agreement_parsers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation (Senses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison to Oslopots Scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explicit connectives         : Precision 1.0000 Recall 0.9874 F1 0.9937\n",
      "Arg 1 extractor              : Precision 1.0000 Recall 1.0000 F1 1.0000\n",
      "Arg 2 extractor              : Precision 1.0000 Recall 1.0000 F1 1.0000\n",
      "Arg1 Arg2 extractor combined : Precision 1.0000 Recall 1.0000 F1 1.0000\n",
      "Sense classification--------------\n",
      "*Micro-Average                    precision 0.5485\trecall 0.5476\tF1 0.5480\n",
      "Comparison.Concession             precision 1.0000\trecall 0.0660\tF1 0.1239\n",
      "Comparison.Contrast               precision 0.2160\trecall 0.4909\tF1 0.3000\n",
      "Contingency.Cause.Reason          precision 0.4267\trecall 0.4384\tF1 0.4324\n",
      "Contingency.Cause.Result          precision 0.6000\trecall 0.3000\tF1 0.4000\n",
      "Contingency.Condition             precision 0.8667\trecall 1.0000\tF1 0.9286\n",
      "EntRel                            precision 0.4306\trecall 0.7600\tF1 0.5497\n",
      "Expansion.Alternative             precision 1.0000\trecall 0.3333\tF1 0.5000\n",
      "Expansion.Conjunction             precision 0.6704\trecall 0.7368\tF1 0.7021\n",
      "Expansion.Instantiation           precision 0.6000\trecall 0.1364\tF1 0.2222\n",
      "Expansion.Restatement             precision 0.4923\trecall 0.2133\tF1 0.2977\n",
      "Temporal.Asynchronous.Precedence  precision 0.9048\trecall 0.7600\tF1 0.8261\n",
      "Temporal.Asynchronous.Succession  precision 0.9600\trecall 0.7500\tF1 0.8421\n",
      "Temporal.Synchrony                precision 0.5538\trecall 0.6792\tF1 0.6102\n",
      "Overall parser performance --------------\n",
      "Precision 0.5485 Recall 0.5476 F1 0.5480\n"
     ]
    }
   ],
   "source": [
    "result = scorer.evaluate(test_data,example_parser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Best Wins\"\n",
    "\n",
    "This algorithm focus on the highest reliability for its prediction (F1 Score for its predicted sense)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explicit connectives         : Precision 1.0000 Recall 0.9874 F1 0.9937\n",
      "Arg 1 extractor              : Precision 1.0000 Recall 1.0000 F1 1.0000\n",
      "Arg 2 extractor              : Precision 1.0000 Recall 1.0000 F1 1.0000\n",
      "Arg1 Arg2 extractor combined : Precision 1.0000 Recall 1.0000 F1 1.0000\n",
      "Sense classification--------------\n",
      "*Micro-Average                    precision 0.4334\trecall 0.4334\tF1 0.4334\n",
      "Comparison.Concession             precision 1.0000\trecall 0.0000\tF1 0.0000\n",
      "Comparison.Contrast               precision 0.1360\trecall 0.5636\tF1 0.2191\n",
      "Contingency.Cause.Reason          precision 0.4688\trecall 0.2027\tF1 0.2830\n",
      "Contingency.Cause.Result          precision 0.5000\trecall 0.0204\tF1 0.0392\n",
      "Contingency.Condition             precision 0.7879\trecall 1.0000\tF1 0.8814\n",
      "EntRel                            precision 0.4151\trecall 0.2200\tF1 0.2876\n",
      "Expansion.Alternative             precision 1.0000\trecall 0.3333\tF1 0.5000\n",
      "Expansion.Conjunction             precision 0.4595\trecall 0.8369\tF1 0.5932\n",
      "Expansion.Instantiation           precision 0.4762\trecall 0.2273\tF1 0.3077\n",
      "Expansion.Restatement             precision 0.6667\trecall 0.0132\tF1 0.0260\n",
      "Temporal.Asynchronous.Precedence  precision 0.5063\trecall 0.8000\tF1 0.6202\n",
      "Temporal.Asynchronous.Succession  precision 0.9216\trecall 0.7344\tF1 0.8174\n",
      "Temporal.Synchrony                precision 0.5439\trecall 0.6200\tF1 0.5794\n",
      "Overall parser performance --------------\n",
      "Precision 0.4334 Recall 0.4334 F1 0.4334\n"
     ]
    }
   ],
   "source": [
    "result = scorer.evaluate(test_data,best_wins_relations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Max Agreement\"\n",
    "\n",
    "This algorithm takes the prediction where most of the parsers agree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explicit connectives         : Precision 1.0000 Recall 0.9874 F1 0.9937\n",
      "Arg 1 extractor              : Precision 1.0000 Recall 1.0000 F1 1.0000\n",
      "Arg 2 extractor              : Precision 1.0000 Recall 1.0000 F1 1.0000\n",
      "Arg1 Arg2 extractor combined : Precision 1.0000 Recall 1.0000 F1 1.0000\n",
      "Sense classification--------------\n",
      "*Micro-Average                    precision 0.5485\trecall 0.5476\tF1 0.5480\n",
      "Comparison.Concession             precision 1.0000\trecall 0.0660\tF1 0.1239\n",
      "Comparison.Contrast               precision 0.2160\trecall 0.4909\tF1 0.3000\n",
      "Contingency.Cause.Reason          precision 0.4267\trecall 0.4384\tF1 0.4324\n",
      "Contingency.Cause.Result          precision 0.6000\trecall 0.3000\tF1 0.4000\n",
      "Contingency.Condition             precision 0.8667\trecall 1.0000\tF1 0.9286\n",
      "EntRel                            precision 0.4306\trecall 0.7600\tF1 0.5497\n",
      "Expansion.Alternative             precision 1.0000\trecall 0.3333\tF1 0.5000\n",
      "Expansion.Conjunction             precision 0.6704\trecall 0.7368\tF1 0.7021\n",
      "Expansion.Instantiation           precision 0.6000\trecall 0.1364\tF1 0.2222\n",
      "Expansion.Restatement             precision 0.4923\trecall 0.2133\tF1 0.2977\n",
      "Temporal.Asynchronous.Precedence  precision 0.9048\trecall 0.7600\tF1 0.8261\n",
      "Temporal.Asynchronous.Succession  precision 0.9600\trecall 0.7500\tF1 0.8421\n",
      "Temporal.Synchrony                precision 0.5538\trecall 0.6792\tF1 0.6102\n",
      "Overall parser performance --------------\n",
      "Precision 0.5485 Recall 0.5476 F1 0.5480\n"
     ]
    }
   ],
   "source": [
    "result = scorer.evaluate(test_data,max_agreement_relations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
