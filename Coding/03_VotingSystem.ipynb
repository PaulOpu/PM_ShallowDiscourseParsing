{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting Systems\n",
    "\n",
    "In this notebook we compare different voting systems to get the final prediction. Our models were trained on the blind test data, that is not biased by the training process and use the dev-test data to test our model.\n",
    "\n",
    "## Load Test Data and Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "from read_write_files import read_json,save_json,get_parser_paths\n",
    "from helper_functions import get_sense_lists,align_parsers_to_gold,plot_confusion_matrix\n",
    "import numpy as np\n",
    "import conll16st.scorer as scorer\n",
    "import conll16st.partial_scorer as partial_scorer\n",
    "import random\n",
    "from collections import Counter\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "sense_model_path = \"data/project_files/test/sense_model.json\"\n",
    "total_alignment_path = \"data/project_files/blind/total_alignment.json\"\n",
    "test_data_path = \"data/gold_standard/blind/relations.json\"\n",
    "example_parser_path = \"data/submissions/sense_only/blind/oslopots/output/output.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_alignments = read_json(total_alignment_path)\n",
    "sense_model = read_json(sense_model_path)\n",
    "test_data = read_json(test_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_parser = read_json(example_parser_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_senses,parser_senses,parser_names = get_sense_lists(total_alignments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting Systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def voting(parser_preds,parser_names,model,voting_algorithm):\n",
    "    new_senses = []\n",
    "    \n",
    "    parser_pred_zip = zip(*parser_preds)\n",
    "    for predictions in parser_pred_zip:\n",
    "        result = voting_algorithm(predictions,model)\n",
    "        new_senses += [result]\n",
    "        \n",
    "    return new_senses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_wins_voting(predictions,model):\n",
    "    probs = []\n",
    "    sense_predictions = []\n",
    "    for ind,pred in enumerate(predictions):\n",
    "        sense_predictions += [pred]\n",
    "        sense_dic = model[ind][\"sense_pred\"]\n",
    "        if (pred == \"None\") or not (sense_dic.has_key(pred)):\n",
    "            probs += [0]\n",
    "        else:\n",
    "            probs += [sense_dic[pred][\"f1\"]]\n",
    "            \n",
    "    result = np.argmax(probs)\n",
    "    if sum(probs) == 0:\n",
    "        result = -1\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_agreement(predictions,model):\n",
    "    sense_counter = Counter(predictions)\n",
    "    best_sense = sense_counter.most_common(1)[0][0]\n",
    "\n",
    "    if best_sense == \"None\":\n",
    "        return -1\n",
    "    \n",
    "    return predictions.index(best_sense) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_maximation(predictions,model):\n",
    "    \n",
    "    sense_probs = {pred:[] for pred in set(predictions)}\n",
    "    \n",
    "    for pred,tmp_model in zip(*[predictions,model]):\n",
    "        if pred != \"None\":\n",
    "            sense_probs[pred] += [tmp_model[\"sense_pred\"][pred][\"f1\"]]\n",
    "    \n",
    "    maxi = 0\n",
    "    best_sense = \"None\"\n",
    "    for sense in sense_probs:\n",
    "        sense_probs[sense] = sum(sense_probs[sense])\n",
    "        if sense_probs[sense] > maxi:\n",
    "            best_sense = sense\n",
    "    \n",
    "\n",
    "    if best_sense == \"None\":\n",
    "        return -1\n",
    "    else:\n",
    "        return predictions.index(best_sense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def three_best_agreement(predictions,model):\n",
    "    weighting = [tmp_model[\"weight\"] for tmp_model in model]\n",
    "    \n",
    "    best_model_indexes = []\n",
    "    for i in range(3):\n",
    "        best_model_indexes += weighting.pop(np.argmax(weighting))\n",
    "        \n",
    "    predictions = [pred for ind,pred in enumerate(predictions) if ind in best_model_indexes]\n",
    "    new_model = copy.deepcopy(model)\n",
    "    new_model = [tmp_model for ind,tmp_model in enumerate(new_model) if ind in best_model_indexes]\n",
    "    \n",
    "    return max_agreement(predictions,new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_wins_parsers = voting(parser_senses,parser_names,sense_model,best_wins_voting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_agreement_parsers = voting(parser_senses,parser_names,sense_model,max_agreement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_maximation_parsers = voting(parser_senses,parser_names,sense_model,prob_maximation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'weight'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-192-476d778be84d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mthree_best_agreement_parsers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvoting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparser_senses\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparser_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msense_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mthree_best_agreement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-84-4819ab9895ae>\u001b[0m in \u001b[0;36mvoting\u001b[0;34m(parser_preds, parser_names, model, voting_algorithm)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mparser_pred_zip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mparser_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparser_pred_zip\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvoting_algorithm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mnew_senses\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-188-eed04fe5f21c>\u001b[0m in \u001b[0;36mthree_best_agreement\u001b[0;34m(predictions, model)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mthree_best_agreement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mweighting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtmp_model\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"weight\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtmp_model\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mbest_model_indexes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'weight'"
     ]
    }
   ],
   "source": [
    "three_best_agreement_parsers = voting(parser_senses,parser_names,sense_model,three_best_agreement)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exchange new Attributes in Relation File\n",
    "\n",
    "Only for sense evaluation, because we take the arg span from the gold file to have a clear mapping between the gold and the prediction (only sense is exchanged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exchange_sense_values(parser_rel,alignment_list,best_relation_indexes):\n",
    "    relation_senses = {}\n",
    "    \n",
    "    for best_parser,alignments in zip(*[best_relation_indexes,alignment_list]):\n",
    "        \n",
    "        if best_parser != -1:\n",
    "            best_sense = alignments[\"parsers\"][best_parser][\"Sense\"]\n",
    "            \n",
    "            relation_senses[alignments[\"gold\"][\"ID\"]] = best_sense\n",
    "    \n",
    "    new_parser_rel = copy.deepcopy(parser_rel)\n",
    "    for rel in new_parser_rel:\n",
    "        rel_id = rel[\"ID\"]\n",
    "        if rel_id in relation_senses:\n",
    "            rel[\"Sense\"] = relation_senses[rel_id] \n",
    "\n",
    "    return new_parser_rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_wins_relations = exchange_sense_values(example_parser,total_alignments,best_wins_parsers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_agreement_relations = exchange_sense_values(example_parser,total_alignments,max_agreement_parsers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_maximation_relations = exchange_sense_values(example_parser,total_alignments,prob_maximation_parsers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation (Senses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison to Oslopots Scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explicit connectives         : Precision 1.0000 Recall 0.9874 F1 0.9937\n",
      "Arg 1 extractor              : Precision 1.0000 Recall 1.0000 F1 1.0000\n",
      "Arg 2 extractor              : Precision 1.0000 Recall 1.0000 F1 1.0000\n",
      "Arg1 Arg2 extractor combined : Precision 1.0000 Recall 1.0000 F1 1.0000\n",
      "Sense classification--------------\n",
      "*Micro-Average                    precision 0.5485\trecall 0.5476\tF1 0.5480\n",
      "Comparison.Concession             precision 1.0000\trecall 0.0660\tF1 0.1239\n",
      "Comparison.Contrast               precision 0.2160\trecall 0.4909\tF1 0.3000\n",
      "Contingency.Cause.Reason          precision 0.4267\trecall 0.4384\tF1 0.4324\n",
      "Contingency.Cause.Result          precision 0.6000\trecall 0.3000\tF1 0.4000\n",
      "Contingency.Condition             precision 0.8667\trecall 1.0000\tF1 0.9286\n",
      "EntRel                            precision 0.4306\trecall 0.7600\tF1 0.5497\n",
      "Expansion.Alternative             precision 1.0000\trecall 0.3333\tF1 0.5000\n",
      "Expansion.Conjunction             precision 0.6704\trecall 0.7368\tF1 0.7021\n",
      "Expansion.Instantiation           precision 0.6000\trecall 0.1364\tF1 0.2222\n",
      "Expansion.Restatement             precision 0.4923\trecall 0.2133\tF1 0.2977\n",
      "Temporal.Asynchronous.Precedence  precision 0.9048\trecall 0.7600\tF1 0.8261\n",
      "Temporal.Asynchronous.Succession  precision 0.9600\trecall 0.7500\tF1 0.8421\n",
      "Temporal.Synchrony                precision 0.5538\trecall 0.6792\tF1 0.6102\n",
      "Overall parser performance --------------\n",
      "Precision 0.5485 Recall 0.5476 F1 0.5480\n"
     ]
    }
   ],
   "source": [
    "result = scorer.evaluate(test_data,example_parser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Best Wins\"\n",
    "\n",
    "This algorithm focus on the highest reliability for its prediction (F1 Score for its predicted sense)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explicit connectives         : Precision 1.0000 Recall 0.9874 F1 0.9937\n",
      "Arg 1 extractor              : Precision 1.0000 Recall 1.0000 F1 1.0000\n",
      "Arg 2 extractor              : Precision 1.0000 Recall 1.0000 F1 1.0000\n",
      "Arg1 Arg2 extractor combined : Precision 1.0000 Recall 1.0000 F1 1.0000\n",
      "Sense classification--------------\n",
      "*Micro-Average                    precision 0.4334\trecall 0.4334\tF1 0.4334\n",
      "Comparison.Concession             precision 1.0000\trecall 0.0000\tF1 0.0000\n",
      "Comparison.Contrast               precision 0.1360\trecall 0.5636\tF1 0.2191\n",
      "Contingency.Cause.Reason          precision 0.4688\trecall 0.2027\tF1 0.2830\n",
      "Contingency.Cause.Result          precision 0.5000\trecall 0.0204\tF1 0.0392\n",
      "Contingency.Condition             precision 0.7879\trecall 1.0000\tF1 0.8814\n",
      "EntRel                            precision 0.4151\trecall 0.2200\tF1 0.2876\n",
      "Expansion.Alternative             precision 1.0000\trecall 0.3333\tF1 0.5000\n",
      "Expansion.Conjunction             precision 0.4595\trecall 0.8369\tF1 0.5932\n",
      "Expansion.Instantiation           precision 0.4762\trecall 0.2273\tF1 0.3077\n",
      "Expansion.Restatement             precision 0.6667\trecall 0.0132\tF1 0.0260\n",
      "Temporal.Asynchronous.Precedence  precision 0.5063\trecall 0.8000\tF1 0.6202\n",
      "Temporal.Asynchronous.Succession  precision 0.9216\trecall 0.7344\tF1 0.8174\n",
      "Temporal.Synchrony                precision 0.5439\trecall 0.6200\tF1 0.5794\n",
      "Overall parser performance --------------\n",
      "Precision 0.4334 Recall 0.4334 F1 0.4334\n"
     ]
    }
   ],
   "source": [
    "result = scorer.evaluate(test_data,best_wins_relations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Max Agreement\"\n",
    "\n",
    "This algorithm takes the prediction where most of the parsers agree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explicit connectives         : Precision 1.0000 Recall 0.9874 F1 0.9937\n",
      "Arg 1 extractor              : Precision 1.0000 Recall 1.0000 F1 1.0000\n",
      "Arg 2 extractor              : Precision 1.0000 Recall 1.0000 F1 1.0000\n",
      "Arg1 Arg2 extractor combined : Precision 1.0000 Recall 1.0000 F1 1.0000\n",
      "Sense classification--------------\n",
      "*Micro-Average                    precision 0.5559\trecall 0.5550\tF1 0.5555\n",
      "Comparison.Concession             precision 1.0000\trecall 0.0660\tF1 0.1239\n",
      "Comparison.Contrast               precision 0.2500\trecall 0.4909\tF1 0.3313\n",
      "Contingency.Cause.Reason          precision 0.4051\trecall 0.4384\tF1 0.4211\n",
      "Contingency.Cause.Result          precision 0.5926\trecall 0.3200\tF1 0.4156\n",
      "Contingency.Condition             precision 0.9286\trecall 1.0000\tF1 0.9630\n",
      "EntRel                            precision 0.4262\trecall 0.7800\tF1 0.5512\n",
      "Expansion.Alternative             precision 1.0000\trecall 0.3333\tF1 0.5000\n",
      "Expansion.Conjunction             precision 0.6839\trecall 0.7368\tF1 0.7094\n",
      "Expansion.Instantiation           precision 0.5455\trecall 0.1364\tF1 0.2182\n",
      "Expansion.Restatement             precision 0.4789\trecall 0.2267\tF1 0.3077\n",
      "Temporal.Asynchronous.Precedence  precision 0.9512\trecall 0.7800\tF1 0.8571\n",
      "Temporal.Asynchronous.Succession  precision 0.9600\trecall 0.7500\tF1 0.8421\n",
      "Temporal.Synchrony                precision 0.5606\trecall 0.6981\tF1 0.6218\n",
      "Overall parser performance --------------\n",
      "Precision 0.5559 Recall 0.5550 F1 0.5555\n"
     ]
    }
   ],
   "source": [
    "result = scorer.evaluate(test_data,max_agreement_relations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Prob Maximation\"\n",
    "\n",
    "This algorithm sums up the reliability of all parsers that agree with each other and takes the sense with the highest score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explicit connectives         : Precision 1.0000 Recall 0.9874 F1 0.9937\n",
      "Arg 1 extractor              : Precision 1.0000 Recall 1.0000 F1 1.0000\n",
      "Arg 2 extractor              : Precision 1.0000 Recall 1.0000 F1 1.0000\n",
      "Arg1 Arg2 extractor combined : Precision 1.0000 Recall 1.0000 F1 1.0000\n",
      "Sense classification--------------\n",
      "*Micro-Average                    precision 0.2366\trecall 0.2366\tF1 0.2366\n",
      "Comparison.Concession             precision 0.5000\trecall 0.0187\tF1 0.0360\n",
      "Comparison.Contrast               precision 0.1000\trecall 0.0741\tF1 0.0851\n",
      "Contingency.Cause.Reason          precision 0.0286\trecall 0.0132\tF1 0.0180\n",
      "Contingency.Cause.Result          precision 1.0000\trecall 0.0000\tF1 0.0000\n",
      "Contingency.Condition             precision 0.8125\trecall 0.5000\tF1 0.6190\n",
      "EntRel                            precision 0.1944\trecall 0.0700\tF1 0.1029\n",
      "Expansion.Alternative             precision 1.0000\trecall 0.0000\tF1 0.0000\n",
      "Expansion.Conjunction             precision 0.5647\trecall 0.1500\tF1 0.2370\n",
      "Expansion.Instantiation           precision 0.2222\trecall 0.1364\tF1 0.1690\n",
      "Expansion.Restatement             precision 0.2169\trecall 0.8146\tF1 0.3426\n",
      "Temporal.Asynchronous.Precedence  precision 1.0000\trecall 0.0816\tF1 0.1509\n",
      "Temporal.Asynchronous.Succession  precision 0.7273\trecall 0.3871\tF1 0.5053\n",
      "Temporal.Synchrony                precision 0.1442\trecall 0.8868\tF1 0.2480\n",
      "Overall parser performance --------------\n",
      "Precision 0.2366 Recall 0.2366 F1 0.2366\n"
     ]
    }
   ],
   "source": [
    "result = scorer.evaluate(test_data,prob_maximation_relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
