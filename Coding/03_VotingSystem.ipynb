{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting Systems\n",
    "\n",
    "In this notebook we compare different voting systems to get the final prediction. Our models were trained on the blind test data, that is not biased by the training process and use the dev-test data to test our model.\n",
    "\n",
    "## Load Test Data and Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from read_write_files import read_json,save_json,get_parser_paths\n",
    "from helper_functions import get_sense_lists,align_parsers_to_gold\n",
    "import numpy as np\n",
    "import conll16st.scorer as scorer\n",
    "import random\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "sense_model_path = \"data/project_files/test/sense_model.json\"\n",
    "total_alignment_path = \"data/project_files/blind/total_alignment.json\"\n",
    "test_data_path = \"data/gold_standard/blind/relations.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_alignments = read_json(total_alignment_path)\n",
    "sense_model = read_json(sense_model_path)\n",
    "test_data = read_json(test_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_senses,parser_senses,parser_names = get_sense_lists(total_alignments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting Systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def voting(parser_preds,parser_names,model,voting_algorithm):\n",
    "    new_senses = []\n",
    "    \n",
    "    parser_pred_zip = zip(*parser_preds)\n",
    "    for predictions in parser_pred_zip:\n",
    "        result = voting_algorithm(predictions,model)\n",
    "        new_senses += [result]\n",
    "        \n",
    "    return new_senses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_wins_voting(predictions,model):\n",
    "    probs = []\n",
    "    sense_predictions = []\n",
    "    for ind,pred in enumerate(predictions):\n",
    "        sense_predictions += [pred]\n",
    "        sense_dic = model[ind][\"sense_pred\"]\n",
    "        if (pred == \"None\") or not (sense_dic.has_key(pred)):\n",
    "            probs += [0]\n",
    "        else:\n",
    "            probs += [sense_dic[pred][\"f1\"]]\n",
    "            \n",
    "    result = np.argmax(probs)\n",
    "    \n",
    "    if sum(probs) == 0:\n",
    "        result = -1\n",
    "    #    sense_counter = Counter(sense_predictions)\n",
    "    #    best_sense = a.most_common(1)[0][0]\n",
    "    #    probs\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_parser_indexes = voting(parser_senses,parser_names,sense_model,best_wins_voting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exchange new Attributes in Relation File\n",
    "\n",
    "Only for sense evaluation, because we take the arg span from the gold file to have a clear mapping between the gold and the prediction (only sense is exchanged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exchange_sense_values(alignment_list,best_relation_indexes):\n",
    "    new_relations = []\n",
    "    \n",
    "    for best_parser,alignments in zip(*[best_relation_indexes,alignment_list]):\n",
    "        if best_parser != -1:\n",
    "            new_rel = alignments[\"parsers\"][best_parser]\n",
    "            \n",
    "            #best_sense = best_parser_result[\"Sense\"][0]\n",
    "            #new_rel = alignments[\"gold\"].copy()\n",
    "            #new_rel[\"Sense\"] = best_sense\n",
    "        \n",
    "            new_relations.append(new_rel)\n",
    "        \n",
    "    return new_relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_relations = exchange_sense_values(total_alignments,best_parser_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explicit connectives         : Precision 0.8403 Recall 0.7572 F1 0.7966\n",
      "Arg 1 extractor              : Precision 0.8224 Recall 0.8197 F1 0.8210\n",
      "Arg 2 extractor              : Precision 0.8108 Recall 0.8081 F1 0.8094\n",
      "Arg1 Arg2 extractor combined : Precision 0.6988 Recall 0.6964 F1 0.6976\n",
      "Sense classification--------------\n",
      "*Micro-Average                    precision 0.2988\trecall 0.2978\tF1 0.2983\n",
      "Comparison.Concession             precision 1.0000\trecall 0.0000\tF1 0.0000\n",
      "Comparison.Contrast               precision 0.0965\trecall 0.4074\tF1 0.1560\n",
      "Contingency.Cause.Reason          precision 0.1935\trecall 0.0800\tF1 0.1132\n",
      "Contingency.Cause.Result          precision 0.5000\trecall 0.0204\tF1 0.0392\n",
      "Contingency.Condition             precision 0.5312\trecall 0.6538\tF1 0.5862\n",
      "EntRel                            precision 0.2736\trecall 0.1450\tF1 0.1895\n",
      "Expansion.Alternative             precision 1.0000\trecall 0.3333\tF1 0.5000\n",
      "Expansion.Conjunction             precision 0.3260\trecall 0.5920\tF1 0.4205\n",
      "Expansion.Instantiation           precision 0.1905\trecall 0.0909\tF1 0.1231\n",
      "Expansion.Restatement             precision 0.5000\trecall 0.0066\tF1 0.0131\n",
      "Temporal.Asynchronous.Precedence  precision 0.3718\trecall 0.5800\tF1 0.4531\n",
      "Temporal.Asynchronous.Succession  precision 0.6471\trecall 0.5238\tF1 0.5789\n",
      "Temporal.Synchrony                precision 0.3509\trecall 0.4000\tF1 0.3738\n",
      "Overall parser performance --------------\n",
      "Precision 0.2988 Recall 0.2978 F1 0.2983\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<conll16st.confusion_matrix.ConfusionMatrix at 0x1085e2e90>,\n",
       " <conll16st.confusion_matrix.ConfusionMatrix at 0x10bc23050>,\n",
       " <conll16st.confusion_matrix.ConfusionMatrix at 0x105642a10>,\n",
       " <conll16st.confusion_matrix.ConfusionMatrix at 0x1083de710>,\n",
       " <conll16st.confusion_matrix.ConfusionMatrix at 0x1083de8d0>,\n",
       " 0.2988,\n",
       " 0.2978,\n",
       " 0.2983)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scorer.evaluate(test_data,new_relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explicit connectives         : Precision 1.0000 Recall 0.9874 F1 0.9937\n",
      "Arg 1 extractor              : Precision 1.0000 Recall 1.0000 F1 1.0000\n",
      "Arg 2 extractor              : Precision 1.0000 Recall 1.0000 F1 1.0000\n",
      "Arg1 Arg2 extractor combined : Precision 1.0000 Recall 1.0000 F1 1.0000\n",
      "Sense classification--------------\n",
      "*Micro-Average                    precision 0.5360\trecall 0.5352\tF1 0.5356\n",
      "Comparison.Concession             precision 1.0000\trecall 0.0660\tF1 0.1239\n",
      "Comparison.Contrast               precision 0.2347\trecall 0.4182\tF1 0.3007\n",
      "Contingency.Cause.Reason          precision 0.4706\trecall 0.4384\tF1 0.4539\n",
      "Contingency.Cause.Result          precision 0.5455\trecall 0.2449\tF1 0.3380\n",
      "Contingency.Condition             precision 0.9286\trecall 1.0000\tF1 0.9630\n",
      "EntRel                            precision 0.3824\trecall 0.7150\tF1 0.4983\n",
      "Expansion.Alternative             precision 1.0000\trecall 0.3333\tF1 0.5000\n",
      "Expansion.Conjunction             precision 0.6512\trecall 0.7377\tF1 0.6918\n",
      "Expansion.Instantiation           precision 0.3750\trecall 0.0682\tF1 0.1154\n",
      "Expansion.Restatement             precision 0.4512\trecall 0.2450\tF1 0.3176\n",
      "Temporal.Asynchronous.Precedence  precision 0.9737\trecall 0.7400\tF1 0.8409\n",
      "Temporal.Asynchronous.Succession  precision 0.9592\trecall 0.7344\tF1 0.8319\n",
      "Temporal.Synchrony                precision 0.5902\trecall 0.6923\tF1 0.6372\n",
      "Overall parser performance --------------\n",
      "Precision 0.5360 Recall 0.5352 F1 0.5356\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<conll16st.confusion_matrix.ConfusionMatrix at 0x10c16fd50>,\n",
       " <conll16st.confusion_matrix.ConfusionMatrix at 0x1083dec50>,\n",
       " <conll16st.confusion_matrix.ConfusionMatrix at 0x1083de9d0>,\n",
       " <conll16st.confusion_matrix.ConfusionMatrix at 0x1083de850>,\n",
       " <conll16st.confusion_matrix.ConfusionMatrix at 0x1083deb90>,\n",
       " 0.536,\n",
       " 0.5352,\n",
       " 0.5356)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scorer.evaluate(test_data,read_json(\"data/submissions/sense_only/blind/oslopots/output/output.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
