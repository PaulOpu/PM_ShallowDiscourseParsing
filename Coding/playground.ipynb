{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "\n",
    "from conll16st.confusion_matrix import ConfusionMatrix, Alphabet\n",
    "from conll16st.conn_head_mapper import ConnHeadMapper\n",
    "import conll16st.validator as validator\n",
    "\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "CONN_HEAD_MAPPER = ConnHeadMapper()\n",
    "\n",
    "def evaluate(gold_list, predicted_list):\n",
    "    connective_cm = evaluate_connectives(gold_list, predicted_list)\n",
    "    arg1_cm, arg2_cm, rel_arg_cm = evaluate_argument_extractor(gold_list, predicted_list)\n",
    "    sense_cm = evaluate_sense(gold_list, predicted_list)\n",
    "\n",
    "    print 'Explicit connectives         : Precision %1.4f Recall %1.4f F1 %1.4f' % connective_cm.get_prf('yes')\n",
    "    print 'Arg 1 extractor              : Precision %1.4f Recall %1.4f F1 %1.4f' % arg1_cm.get_prf('yes')\n",
    "    print 'Arg 2 extractor              : Precision %1.4f Recall %1.4f F1 %1.4f' % arg2_cm.get_prf('yes')\n",
    "    print 'Arg1 Arg2 extractor combined : Precision %1.4f Recall %1.4f F1 %1.4f' % rel_arg_cm.get_prf('yes')\n",
    "    print 'Sense classification--------------'\n",
    "    sense_cm.print_summary()\n",
    "    print 'Overall parser performance --------------'\n",
    "    precision, recall, f1 = sense_cm.compute_micro_average_f1()\n",
    "    print 'Precision %1.4f Recall %1.4f F1 %1.4f' % (precision, recall, f1)\n",
    "    return connective_cm, arg1_cm, arg2_cm, rel_arg_cm, sense_cm, precision, recall, f1\n",
    "\n",
    "\n",
    "def evaluate_argument_extractor(gold_list, predicted_list):\n",
    "    \"\"\"Evaluate argument extractor at Arg1, Arg2, and relation level\n",
    "\n",
    "    \"\"\"\n",
    "    gold_arg1 = [(x['DocID'], x['Arg1']['TokenList']) for x in gold_list]\n",
    "    predicted_arg1 = [(x['DocID'], x['Arg1']['TokenList']) for x in predicted_list]\n",
    "    arg1_cm = compute_binary_eval_metric(gold_arg1, predicted_arg1, span_exact_matching)\n",
    "\n",
    "    gold_arg2 = [(x['DocID'], x['Arg2']['TokenList']) for x in gold_list]\n",
    "    predicted_arg2 = [(x['DocID'], x['Arg2']['TokenList']) for x in predicted_list]\n",
    "    arg2_cm = compute_binary_eval_metric(gold_arg2, predicted_arg2, span_exact_matching)\n",
    "\n",
    "    gold_arg12 = [(x['DocID'], (x['Arg1']['TokenList'], x['Arg2']['TokenList'])) \\\n",
    "            for x in gold_list]\n",
    "    predicted_arg12 = [(x['DocID'], (x['Arg1']['TokenList'], x['Arg2']['TokenList'])) \\\n",
    "            for x in predicted_list]\n",
    "    rel_arg_cm = compute_binary_eval_metric(gold_arg12, predicted_arg12, spans_exact_matching)\n",
    "    return arg1_cm, arg2_cm, rel_arg_cm\n",
    "\n",
    "def evaluate_connectives(gold_list, predicted_list):\n",
    "    \"\"\"Evaluate connective recognition accuracy for explicit discourse relations\n",
    "\n",
    "    \"\"\"\n",
    "    explicit_gold_list = [(x['DocID'], x['Connective']['TokenList'], x['Connective']['RawText']) \\\n",
    "            for x in gold_list if x['Type'] == 'Explicit']\n",
    "    explicit_predicted_list = [(x['DocID'], x['Connective']['TokenList']) \\\n",
    "            for x in predicted_list if x['Type'] == 'Explicit']\n",
    "    connective_cm = compute_binary_eval_metric(\n",
    "            explicit_gold_list, explicit_predicted_list, connective_head_matching)    \n",
    "    return connective_cm\n",
    "\n",
    "def spans_exact_matching(gold_doc_id_spans, predicted_doc_id_spans):\n",
    "    \"\"\"Matching two lists of spans\n",
    "\n",
    "    Input:\n",
    "        gold_doc_id_spans : (DocID , a list of lists of tuples of token addresses)\n",
    "        predicted_doc_id_spans : (DocID , a list of lists of token indices)\n",
    "\n",
    "    Returns:\n",
    "        True if the spans match exactly\n",
    "    \"\"\"\n",
    "    exact_match = True\n",
    "    gold_docID = gold_doc_id_spans[0]\n",
    "    gold_spans = gold_doc_id_spans[1]\n",
    "    predicted_docID = predicted_doc_id_spans[0]\n",
    "    predicted_spans = predicted_doc_id_spans[1]\n",
    "\n",
    "    for gold_span, predicted_span in zip(gold_spans, predicted_spans):\n",
    "        exact_match = span_exact_matching((gold_docID,gold_span), (predicted_docID, predicted_span)) \\\n",
    "                and exact_match\n",
    "    return exact_match\n",
    "\n",
    "def span_exact_matching(gold_span, predicted_span):\n",
    "    \"\"\"Matching two spans\n",
    "\n",
    "    Input:\n",
    "        gold_span : a list of tuples :(DocID, list of tuples of token addresses)\n",
    "        predicted_span : a list of tuples :(DocID, list of token indices)\n",
    "\n",
    "    Returns:\n",
    "        True if the spans match exactly\n",
    "    \"\"\"\n",
    "    gold_docID = gold_span[0]\n",
    "    predicted_docID = predicted_span[0]\n",
    "    if gold_docID != predicted_docID:\n",
    "        return False\n",
    "    gold_token_indices = [x[2] for x in gold_span[1]]\n",
    "    predicted_token_indices = predicted_span[1]\n",
    "    return gold_docID == predicted_docID and gold_token_indices == predicted_token_indices\n",
    "\n",
    "def connective_head_matching(gold_raw_connective, predicted_raw_connective):\n",
    "    \"\"\"Matching connectives\n",
    "\n",
    "    Input:\n",
    "        gold_raw_connective : (DocID, a list of tuples of token addresses, raw connective token)\n",
    "        predicted_raw_connective : (DocID, a list of tuples of token addresses)\n",
    "\n",
    "    A predicted raw connective is considered iff\n",
    "        1) the predicted raw connective includes the connective \"head\"\n",
    "        2) the predicted raw connective tokens are the subset of predicted raw connective tokens\n",
    "\n",
    "    For example:\n",
    "        connective_head_matching('two weeks after', 'weeks after')  --> True\n",
    "        connective_head_matching('two weeks after', 'two weeks')  --> False not covering head\n",
    "        connective_head_matching('just because', 'because')  --> True\n",
    "        connective_head_matching('just because', 'simply because')  --> False not subset\n",
    "        connective_head_matching('just because', 'since')  --> False\n",
    "    \"\"\"\n",
    "    gold_docID, gold_token_address_list, gold_tokens = gold_raw_connective\n",
    "    predicted_docID, predicted_token_list = predicted_raw_connective\n",
    "    if gold_docID != predicted_docID:\n",
    "        return False\n",
    "\n",
    "    gold_token_indices = [x[2] for x in gold_token_address_list]\n",
    "\n",
    "    if gold_token_address_list == predicted_token_list:\n",
    "        return True\n",
    "    elif not set(predicted_token_list).issubset(set(gold_token_indices)):\n",
    "        return False\n",
    "    else:\n",
    "        conn_head, indices = CONN_HEAD_MAPPER.map_raw_connective(gold_tokens)\n",
    "        gold_head_connective_indices = [gold_token_indices[x] for x in indices]\n",
    "        return set(gold_head_connective_indices).issubset(set(predicted_token_list))\n",
    "\n",
    "def evaluate_sense(gold_list, predicted_list):\n",
    "    \"\"\"Evaluate sense classifier\n",
    "\n",
    "    The label ConfusionMatrix.NEGATIVE_CLASS is for the relations \n",
    "    that are missed by the system\n",
    "    because the arguments don't match any of the gold relations.\n",
    "    \"\"\"\n",
    "    sense_alphabet = Alphabet()\n",
    "    valid_senses = validator.identify_valid_senses(gold_list)\n",
    "    for relation in gold_list:\n",
    "        sense = relation['Sense'][0]\n",
    "        if sense in valid_senses:\n",
    "            sense_alphabet.add(sense)\n",
    "\n",
    "    sense_alphabet.add(ConfusionMatrix.NEGATIVE_CLASS)\n",
    "\n",
    "    sense_cm = ConfusionMatrix(sense_alphabet)\n",
    "    gold_to_predicted_map, predicted_to_gold_map = \\\n",
    "            _link_gold_predicted(gold_list, predicted_list, spans_exact_matching)\n",
    "\n",
    "    for i, gold_relation in enumerate(gold_list):\n",
    "        gold_sense = gold_relation['Sense'][0]\n",
    "        if gold_sense in valid_senses:\n",
    "            if i in gold_to_predicted_map:\n",
    "                predicted_sense = gold_to_predicted_map[i]['Sense'][0]\n",
    "                if predicted_sense in gold_relation['Sense']:\n",
    "                    sense_cm.add(predicted_sense, predicted_sense)\n",
    "                else:\n",
    "                    if not sense_cm.alphabet.has_label(predicted_sense):\n",
    "                        predicted_sense = ConfusionMatrix.NEGATIVE_CLASS\n",
    "                    sense_cm.add(predicted_sense, gold_sense)\n",
    "            else:\n",
    "                sense_cm.add(ConfusionMatrix.NEGATIVE_CLASS, gold_sense)\n",
    "\n",
    "    for i, predicted_relation in enumerate(predicted_list):\n",
    "        if i not in predicted_to_gold_map:\n",
    "            predicted_sense = predicted_relation['Sense'][0]\n",
    "            if not sense_cm.alphabet.has_label(predicted_sense):\n",
    "                predicted_sense = ConfusionMatrix.NEGATIVE_CLASS\n",
    "            sense_cm.add(predicted_sense, ConfusionMatrix.NEGATIVE_CLASS)\n",
    "    return sense_cm\n",
    "\n",
    "\n",
    "def combine_spans(span1, span2):\n",
    "    \"\"\"Merge two text span dictionaries\n",
    "\n",
    "    \"\"\"\n",
    "    new_span = {}\n",
    "    new_span['CharacterSpanList'] = span1['CharacterSpanList'] + span2['CharacterSpanList']\n",
    "    new_span['SpanList'] = span1['SpanList'] + span2['SpanList']\n",
    "    new_span['RawText'] = span1['RawText'] + span2['RawText']\n",
    "    new_span['TokenList'] = span1['TokenList'] + span2['TokenList']\n",
    "    return new_span\n",
    "\n",
    "def compute_binary_eval_metric(gold_list, predicted_list, matching_fn):\n",
    "    \"\"\"Compute binary evaluation metric\n",
    "\n",
    "    \"\"\"\n",
    "    binary_alphabet = Alphabet()\n",
    "    binary_alphabet.add('yes')\n",
    "    binary_alphabet.add('no')\n",
    "    cm = ConfusionMatrix(binary_alphabet)\n",
    "    matched_predicted = [False for x in predicted_list]\n",
    "    for gold_span in gold_list:\n",
    "        found_match = False\n",
    "        for i, predicted_span in enumerate(predicted_list):\n",
    "            if matching_fn(gold_span, predicted_span) and not matched_predicted[i]:\n",
    "                cm.add('yes', 'yes')\n",
    "                matched_predicted[i] = True\n",
    "                found_match = True\n",
    "                break\n",
    "        if not found_match:\n",
    "            cm.add('no', 'yes')\n",
    "    # Predicted span that does not match with any\n",
    "    for matched in matched_predicted:\n",
    "        if not matched:\n",
    "            cm.add('yes', 'no')\n",
    "    return cm\n",
    "\n",
    "\n",
    "def _link_gold_predicted(gold_list, predicted_list, matching_fn):\n",
    "    \"\"\"Link gold standard relations to the predicted relations\n",
    "\n",
    "    A pair of relations are linked when the arg1 and the arg2 match exactly.\n",
    "    We do this because we want to evaluate sense classification later.\n",
    "\n",
    "    Returns:\n",
    "        A tuple of two dictionaries:\n",
    "        1) mapping from gold relation index to predicted relation index\n",
    "        2) mapping from predicted relation index to gold relation index\n",
    "    \"\"\"\n",
    "    gold_to_predicted_map = {}\n",
    "    predicted_to_gold_map = {}\n",
    "    gold_arg12_list = [(x['DocID'], (x['Arg1']['TokenList'], x['Arg2']['TokenList']))\n",
    "            for x in gold_list]\n",
    "    predicted_arg12_list = [(x['DocID'], (x['Arg1']['TokenList'], x['Arg2']['TokenList']))\n",
    "            for x in predicted_list]\n",
    "    for gi, gold_span in enumerate(gold_arg12_list):\n",
    "        for pi, predicted_span in enumerate(predicted_arg12_list):\n",
    "            if matching_fn(gold_span, predicted_span):\n",
    "                gold_to_predicted_map[gi] = predicted_list[pi]\n",
    "                predicted_to_gold_map[pi] = gold_list[gi]\n",
    "    return gold_to_predicted_map, predicted_to_gold_map\n",
    "\n",
    "\n",
    "def main(gold,predicted):\n",
    "    #parser = argparse.ArgumentParser(\n",
    "    #    description=\"Evaluate system's output against the gold standard\")\n",
    "    #parser.add_argument('gold', help='Gold standard file')\n",
    "    #parser.add_argument('predicted', help='System output file')\n",
    "    #args = parser.parse_args()\n",
    "    gold_list = [json.loads(x) for x in open(gold)]\n",
    "    predicted_list = [json.loads(x) for x in open(predicted)]\n",
    "    print '\\n================================================'\n",
    "    print 'Evaluation for all discourse relations'\n",
    "    evaluate(gold_list, predicted_list)\n",
    "\n",
    "    print '\\n================================================'\n",
    "    print 'Evaluation for explicit discourse relations only'\n",
    "    explicit_gold_list = [x for x in gold_list if x['Type'] == 'Explicit']\n",
    "    explicit_predicted_list = [x for x in predicted_list if x['Type'] == 'Explicit']\n",
    "    evaluate(explicit_gold_list, explicit_predicted_list)\n",
    "\n",
    "    print '\\n================================================'\n",
    "    print 'Evaluation for non-explicit discourse relations only (Implicit, EntRel, AltLex)'\n",
    "    non_explicit_gold_list = [x for x in gold_list if x['Type'] != 'Explicit']\n",
    "    non_explicit_predicted_list = [x for x in predicted_list if x['Type'] != 'Explicit']\n",
    "    evaluate(non_explicit_gold_list, non_explicit_predicted_list)\n",
    "    \n",
    "    \n",
    "    \n",
    "def plot_confusion_matrix(y_test,y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "    plt.figure(figsize=(18,18))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functionality Evaluation\n",
    "\n",
    "3 Parts\n",
    "- Connectives\n",
    "- Arg1/Arg2 Span\n",
    "- Sense Validation\n",
    "\n",
    "only exact matching pairs are True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison\n",
    "\n",
    "## Create Unified Formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'Arg1': {u'CharacterSpanList': [[517, 564]],\n",
       "  u'RawText': u'to restrict the RTC to Treasury borrowings only',\n",
       "  u'TokenList': [85, 86, 87, 88, 89, 90, 91, 92]},\n",
       " u'Arg2': {u'CharacterSpanList': [[573, 629]],\n",
       "  u'RawText': u'the agency receives specific congressional authorization',\n",
       "  u'TokenList': [95, 96, 97, 98, 99, 100]},\n",
       " u'Connective': {u'CharacterSpanList': [[566, 572]],\n",
       "  u'RawText': u'unless',\n",
       "  u'TokenList': [94]},\n",
       " u'DocID': u'wsj_2200',\n",
       " u'ID': 35709,\n",
       " u'Sense': [u'Expansion.Alternative'],\n",
       " u'Type': u'Explicit'}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in stepanov_predicted_list if i['Type'] == 'Explicit' and i['DocID'] == 'wsj_2200'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'Arg1': {u'CharacterSpanList': [[517, 564]],\n",
       "  u'RawText': u'to restrict the RTC to Treasury borrowings only',\n",
       "  u'TokenList': [[517, 519, 85, 2, 3],\n",
       "   [520, 528, 86, 2, 4],\n",
       "   [529, 532, 87, 2, 5],\n",
       "   [533, 536, 88, 2, 6],\n",
       "   [537, 539, 89, 2, 7],\n",
       "   [540, 548, 90, 2, 8],\n",
       "   [549, 559, 91, 2, 9],\n",
       "   [560, 564, 92, 2, 10]]},\n",
       " u'Arg2': {u'CharacterSpanList': [[573, 629]],\n",
       "  u'RawText': u'the agency receives specific congressional authorization',\n",
       "  u'TokenList': [[573, 576, 95, 2, 13],\n",
       "   [577, 583, 96, 2, 14],\n",
       "   [584, 592, 97, 2, 15],\n",
       "   [593, 601, 98, 2, 16],\n",
       "   [602, 615, 99, 2, 17],\n",
       "   [616, 629, 100, 2, 18]]},\n",
       " u'Connective': {u'CharacterSpanList': [[566, 572]],\n",
       "  u'RawText': u'unless',\n",
       "  u'TokenList': [[566, 572, 94, 2, 12]]},\n",
       " u'DocID': u'wsj_2200',\n",
       " u'ID': 35709,\n",
       " u'Sense': [u'Expansion.Alternative'],\n",
       " u'Type': u'Explicit'}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in gold_list if i['Type'] == 'Explicit' and i['DocID'] == 'wsj_2200'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each Relation is defined by:\n",
    "\n",
    "- DocID\n",
    "- Arg1 TokenSpan\n",
    "- Arg2 TokenSpan\n",
    "- Type\n",
    "- Connective (Explicit, maybe Implicit)\n",
    "- Sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_comparison_format(relation,gold=True):\n",
    "    conn = dict(relation[\"Connective\"])\n",
    "    if conn.has_key(\"CharacterSpanList\"):\n",
    "        del conn[\"CharacterSpanList\"]\n",
    "    if not conn.has_key(\"RawText\"):\n",
    "        conn[\"RawText\"] = \"\"\n",
    "    \n",
    "    dic = {\n",
    "        \"DocID\": relation[\"DocID\"],\n",
    "        \"RelID\": relation[\"ID\"],\n",
    "        \"Sense\": relation[\"Sense\"],\n",
    "        \"Type\" : relation[\"Type\"],\n",
    "        \"Connective\": conn   \n",
    "    }\n",
    "    \n",
    "    if gold:\n",
    "        dic[\"Arg1TokenList\"] = [token[2] for token in relation[\"Arg1\"][\"TokenList\"]]\n",
    "        dic[\"Arg2TokenList\"] = [token[2] for token in relation[\"Arg2\"][\"TokenList\"]]\n",
    "        dic[\"Parser\"] = \"Gold\"\n",
    "    else:\n",
    "        dic[\"Arg1TokenList\"] = relation[\"Arg1\"][\"TokenList\"]\n",
    "        dic[\"Arg2TokenList\"] = relation[\"Arg2\"][\"TokenList\"]\n",
    "        dic[\"Parser\"] = \"Pred\"\n",
    "    \n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_comparison_format_to_file(relations,file_path):\n",
    "    with open(file_path, 'w') as f:\n",
    "        json.dump(relations, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_comparison_format_from_file(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "        f.close()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_gold_file_path = \"data/conll2016/en.dev/relations.json\"\n",
    "dev_oslopots_file_path = \"data/submissions/oslopots_dev/output/output.json\"\n",
    "dev_stepanov_file_path = \"data/submissions/stepanov_dev/output/output.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main()\n",
    "gold_list = [json.loads(x) for x in open(dev_gold_file_path)]\n",
    "oslopots_predicted_list = [json.loads(x) for x in open(dev_oslopots_file_path)]\n",
    "stepanov_predicted_list = [json.loads(x) for x in open(dev_stepanov_file_path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [(\"oslopots\",oslopots_predicted_list),(\"stepanov\",stepanov_predicted_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_relations = [create_comparison_format(gold,True) for gold in gold_list]\n",
    "write_comparison_format_to_file(gold_relations,\"data/project_files/dev_gold_relations.json\")\n",
    "\n",
    "for name,prediction in predictions:\n",
    "    relations = [create_comparison_format(pred,False) for pred in prediction]\n",
    "    write_comparison_format_to_file(relations,\"data/project_files/dev_\"+name+\".json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map Relations together\n",
    "\n",
    "Some of the relations are completely equal (because the evaluation only allows exact matching spans), but some only have parts in common or are completely missed by the parsers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "oslopots_relations = read_comparison_format_from_file(\"data/project_files/dev_oslopots.json\")\n",
    "gold_relations = read_comparison_format_from_file(\"data/project_files/dev_gold_relations.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_arg(gold_token,pred_token):\n",
    "    diff = len(\n",
    "        set(pred_token).intersection(set(gold_token))\n",
    "    )/len(\n",
    "        set(pred_token).union(set(gold_token)))\n",
    "    if diff != 1 and diff != 0:\n",
    "        print diff\n",
    "    return diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_gold_pred_rel(gold_list,pred_list):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "docIDs = set([rel[\"DocID\"] for rel in gold_relations])\n",
    "mapping = []\n",
    "for docID in docIDs:\n",
    "    pred_doc_rel = [rel for rel in oslopots_relations if rel['DocID'] == docID]\n",
    "    gold_doc_rel = [rel for rel in gold_relations if rel['DocID'] == docID]\n",
    "\n",
    "    for gold_rel in gold_doc_rel:\n",
    "        gold_arg1 = gold_rel[\"Arg1TokenList\"]\n",
    "        gold_arg2 = gold_rel[\"Arg2TokenList\"]\n",
    "        gold_pred_map = []\n",
    "        for pred_rel in pred_doc_rel:\n",
    "            pred_arg1 = pred_rel[\"Arg1TokenList\"]\n",
    "            pred_arg2 = pred_rel[\"Arg2TokenList\"]\n",
    "            gold_pred_map += [(diff_arg(gold_arg1,pred_arg1)+diff_arg(gold_arg2,pred_arg2))/2]\n",
    "        best_match_index = np.argmax(gold_pred_map)\n",
    "        mapping += [\n",
    "            [gold_rel[\"RelID\"],\n",
    "            pred_doc_rel[best_match_index][\"RelID\"]]\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "found_gold,found_pred = zip(*mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(found_gold)/len(gold_relations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "The recognition of the right spans is most of the times right by the examinated parsers. Therefore, it doesn't help to explore span overlapping anymore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine each relation of Gold and all Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_rel(gold_list,parser_pred):\n",
    "    combinations = {gold[\"RelID\"]:[gold] for gold in gold_list}\n",
    "    for name,prediction in parser_pred:\n",
    "        for pred in prediction:\n",
    "            pred[\"Parser\"] = name\n",
    "            combinations[pred[\"RelID\"]] += [pred]\n",
    "    return combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_senses(parse_pairs):\n",
    "    pair_values = parse_pairs.values()\n",
    "    rows = []\n",
    "    for pair in pair_values:\n",
    "        gold_sense = pair[0][\"Sense\"][0]\n",
    "        all_senses = [gold_sense] + [parse[\"Sense\"][0] for parse in pair[1:]]\n",
    "        rows += [tuple(all_senses)]\n",
    "    \n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sense_statistics(sense_comparison):\n",
    "    zip_sense_comparison = zip(*sense_comparison)\n",
    "    gold_senses = zip_sense_comparison[0]\n",
    "    #Count all combination of senses\n",
    "    sense_counter = Counter(sense_comparison)\n",
    "    #Different Senses\n",
    "    set_senses = set(gold_senses)\n",
    "    #How many parsers will be compared\n",
    "    len_parser = len(zip_sense_comparison)-1\n",
    "    sense_rows = []\n",
    "\n",
    "    for sense in set_senses:\n",
    "        tmp_senses = set_senses.copy()\n",
    "        tmp_senses.remove(sense)\n",
    "        possible_comb = [[sense]] + [tmp_senses for i in range(len_parser)]\n",
    "        diff_preds = product(*possible_comb)\n",
    "\n",
    "        equal_correct_parsing = sense_counter[tuple([sense]+[sense]*len_parser)]\n",
    "\n",
    "        all_wrong_parsing = sum([\n",
    "            sense_counter[tuple(diff_pred)] \n",
    "            for diff_pred in diff_preds])\n",
    "\n",
    "        total_act_sense_count = equal_correct_parsing + sum([1 for i in gold_senses if i == sense])\n",
    "\n",
    "\n",
    "        equal_wrong_parsing = sum([\n",
    "            sense_counter[tuple([sense]+[other_sense]*len_parser)] \n",
    "            for other_sense in tmp_senses])\n",
    "\n",
    "        #Parser is better than all the other\n",
    "        parser_better = []\n",
    "        for index_parser in range(1,len_parser+1):\n",
    "            tmp_possible_comb = possible_comb[:]\n",
    "            tmp_possible_comb[index_parser] = [sense]\n",
    "            other_diff_preds = product(*tmp_possible_comb)\n",
    "            pars_better = sum([sense_counter[other_diff_pred] for other_diff_pred in other_diff_preds])\n",
    "\n",
    "            total_pred_sense_count = sum([1 for i in zip_sense_comparison[index_parser] if i == sense])\n",
    "\n",
    "            parser_better += [pars_better,total_pred_sense_count]\n",
    "\n",
    "        #At least one parser is correct\n",
    "        combination_correct = sum([parser_better[right_parser_pred] for right_parser_pred in range(0,len(parser_better),2)])+equal_correct_parsing\n",
    "\n",
    "        sense_rows += [[sense,equal_correct_parsing,all_wrong_parsing,total_act_sense_count,equal_wrong_parsing,combination_correct]+parser_better]\n",
    "\n",
    "    parser_columns = []\n",
    "    for parser_name in parser_names:\n",
    "        parser_columns += [\"Only {} right\".format(parser_name),\"Total Pred ({})\".format(parser_name)]\n",
    "\n",
    "\n",
    "    return pd.DataFrame(\n",
    "        columns=[\"Sense\",\n",
    "                 \"Equal Correct\",\n",
    "                 \"All Wrong\",\n",
    "                 \"Total Act\",\n",
    "                 \"Equal Wrong\",\n",
    "                 \"At least one correct\"]+parser_columns,\n",
    "        data=sense_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "oslopots_relations = read_comparison_format_from_file(\"data/project_files/dev_oslopots.json\")\n",
    "stepanov_relations = read_comparison_format_from_file(\"data/project_files/dev_stepanov.json\")\n",
    "gold_relations = read_comparison_format_from_file(\"data/project_files/dev_gold_relations.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser_pred = [(\"oslopots\",oslopots_relations),(\"stepanov\",stepanov_relations)]\n",
    "parser_names = [name for name,pred in parser_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb = combine_rel(gold_relations,parser_pred)\n",
    "sense_comparison = compare_senses(comb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   1  19   0   0   0   0   0   0   0   1   0   0   0   0   0   0]\n",
      " [  0   5   6   0   0   1   2   0   0   0   1   0   2   0   0   0   0]\n",
      " [  0   6 164   6   3   0  36   0   0   0  22   0   7   0   0   0   0]\n",
      " [  0   0   0  53   1   0  32   0   0   0   4   0  19   0   1   1   5]\n",
      " [  0   0   2  13  20   0  21   0   0   0   7   0   9   0   0   0   0]\n",
      " [  0   0   0   0   0  43   0   0   0   0   0   0   0   0   1   0   6]\n",
      " [  0   0   1   4   1   0 188   0   0   0  12   1   8   0   0   0   0]\n",
      " [  0   0   0   1   1   0   1   0   0   0   2   0   1   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   6   0   0   0   0   0   0   0   0]\n",
      " [  0   0   1   1   0   0   0   0   0   5   1   0   0   0   0   0   0]\n",
      " [  0   0   8   6   1   0  46   0   1   0 231   1  14   0   0   0   0]\n",
      " [  0   0   1   3   1   0  26   0   0   0   3  13  10   0   0   0   0]\n",
      " [  0   0   1   9   0   0  45   0   0   0  13   1  38   0   1   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1]\n",
      " [  0   0   0   0   0   0  17   0   0   0   8   0   1   0  50   0   0]\n",
      " [  0   0   0   1   0   0   2   0   0   0   0   0   0   0   0  39  12]\n",
      " [  0   0   5  11   0   1   4   0   0   0   3   0   0   0   0   1  52]]\n",
      "\n",
      "\n",
      "\n",
      "[[  0   0  15   2   0   0   1   0   0   0   1   0   0   0   2   0   0]\n",
      " [  0   2   5   1   2   1   2   0   0   0   3   0   0   0   0   0   1]\n",
      " [  0   6 131  10  10   3  29   0   0   0  37   5   0   0   7   2   4]\n",
      " [  0   0  15  29   3   2  19   0   0   0  34   0   3   0   5   1   5]\n",
      " [  0   2   7   3  18   1  14   0   1   0  19   0   0   0   3   3   1]\n",
      " [  0   0   2   1   1  34   1   0   0   0   3   0   0   0   4   0   4]\n",
      " [  0   4  21   4   1   1 127   0   0   1  48   1   0   0   3   4   0]\n",
      " [  0   0   2   0   0   0   2   0   0   0   1   0   0   0   0   0   1]\n",
      " [  0   1   0   0   0   1   0   0   4   0   0   0   0   0   0   0   0]\n",
      " [  0   0   2   0   0   0   0   0   0   3   2   0   0   0   1   0   0]\n",
      " [  0   1  26  10   7   7  42   0   0   0 188   4   6   0   9   1   7]\n",
      " [  0   0   7   4   1   1  19   0   0   0  11   9   0   0   3   1   1]\n",
      " [  0   4  12   4   2   1  31   0   0   0  42   0   1   0   7   1   3]\n",
      " [  0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0]\n",
      " [  0   0   3   1   0   0  10   0   0   0  11   1   0   0  47   2   1]\n",
      " [  0   0   7   2   0   0   6   0   0   1   4   0   0   0   1  26   7]\n",
      " [  0   0  14   1   1   0   7   0   0   1  10   0   1   0   4   3  35]]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gold_senses = zip_sense_comparison[0]\n",
    "parser_senses = zip_sense_comparison[1:]\n",
    "for parser_sense in parser_senses:\n",
    "    cm = confusion_matrix(gold_senses,parser_sense)\n",
    "    print(cm)\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sense</th>\n",
       "      <th>Equal Correct</th>\n",
       "      <th>All Wrong</th>\n",
       "      <th>Total Act</th>\n",
       "      <th>Equal Wrong</th>\n",
       "      <th>At least one correct</th>\n",
       "      <th>Only oslopots right</th>\n",
       "      <th>Total Pred (oslopots)</th>\n",
       "      <th>Only stepanov right</th>\n",
       "      <th>Total Pred (stepanov)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Comparison.Concession</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Comparison</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Expansion.Conjunction</td>\n",
       "      <td>158</td>\n",
       "      <td>47</td>\n",
       "      <td>466</td>\n",
       "      <td>20</td>\n",
       "      <td>261</td>\n",
       "      <td>73</td>\n",
       "      <td>308</td>\n",
       "      <td>30</td>\n",
       "      <td>415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Contingency.Condition</td>\n",
       "      <td>33</td>\n",
       "      <td>6</td>\n",
       "      <td>83</td>\n",
       "      <td>5</td>\n",
       "      <td>44</td>\n",
       "      <td>10</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Expansion.Alternative</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>EntRel</td>\n",
       "      <td>112</td>\n",
       "      <td>12</td>\n",
       "      <td>327</td>\n",
       "      <td>2</td>\n",
       "      <td>203</td>\n",
       "      <td>76</td>\n",
       "      <td>420</td>\n",
       "      <td>15</td>\n",
       "      <td>310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Contingency.Cause.Result</td>\n",
       "      <td>16</td>\n",
       "      <td>50</td>\n",
       "      <td>88</td>\n",
       "      <td>11</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Contingency.Cause.Reason</td>\n",
       "      <td>26</td>\n",
       "      <td>60</td>\n",
       "      <td>142</td>\n",
       "      <td>14</td>\n",
       "      <td>56</td>\n",
       "      <td>27</td>\n",
       "      <td>108</td>\n",
       "      <td>3</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Expansion</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Temporal</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Temporal.Asynchronous.Succession</td>\n",
       "      <td>25</td>\n",
       "      <td>14</td>\n",
       "      <td>79</td>\n",
       "      <td>8</td>\n",
       "      <td>40</td>\n",
       "      <td>14</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Expansion.Alternative.Chosen alternative</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Temporal.Asynchronous.Precedence</td>\n",
       "      <td>45</td>\n",
       "      <td>24</td>\n",
       "      <td>121</td>\n",
       "      <td>12</td>\n",
       "      <td>52</td>\n",
       "      <td>5</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Expansion.Instantiation</td>\n",
       "      <td>9</td>\n",
       "      <td>44</td>\n",
       "      <td>66</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Comparison.Contrast</td>\n",
       "      <td>117</td>\n",
       "      <td>66</td>\n",
       "      <td>361</td>\n",
       "      <td>25</td>\n",
       "      <td>178</td>\n",
       "      <td>47</td>\n",
       "      <td>208</td>\n",
       "      <td>14</td>\n",
       "      <td>269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Expansion.Restatement</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>109</td>\n",
       "      <td>19</td>\n",
       "      <td>38</td>\n",
       "      <td>37</td>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Temporal.Synchrony</td>\n",
       "      <td>29</td>\n",
       "      <td>19</td>\n",
       "      <td>106</td>\n",
       "      <td>6</td>\n",
       "      <td>58</td>\n",
       "      <td>23</td>\n",
       "      <td>76</td>\n",
       "      <td>6</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Sense  Equal Correct  All Wrong  \\\n",
       "0                      Comparison.Concession              2         12   \n",
       "1                                 Comparison              0         21   \n",
       "2                      Expansion.Conjunction            158         47   \n",
       "3                      Contingency.Condition             33          6   \n",
       "4                      Expansion.Alternative              4          0   \n",
       "5                                     EntRel            112         12   \n",
       "6                   Contingency.Cause.Result             16         50   \n",
       "7                   Contingency.Cause.Reason             26         60   \n",
       "8                                  Expansion              0          6   \n",
       "9                                   Temporal              0          1   \n",
       "10          Temporal.Asynchronous.Succession             25         14   \n",
       "11  Expansion.Alternative.Chosen alternative              3          3   \n",
       "12          Temporal.Asynchronous.Precedence             45         24   \n",
       "13                   Expansion.Instantiation              9         44   \n",
       "14                       Comparison.Contrast            117         66   \n",
       "15                     Expansion.Restatement              1         70   \n",
       "16                        Temporal.Synchrony             29         19   \n",
       "\n",
       "    Total Act  Equal Wrong  At least one correct  Only oslopots right  \\\n",
       "0          19            5                     5                    3   \n",
       "1          21           13                     0                    0   \n",
       "2         466           20                   261                   73   \n",
       "3          83            5                    44                   10   \n",
       "4          10            0                     6                    2   \n",
       "5         327            2                   203                   76   \n",
       "6          88           11                    22                    4   \n",
       "7         142           14                    56                   27   \n",
       "8           6            2                     0                    0   \n",
       "9           1            0                     0                    0   \n",
       "10         79            8                    40                   14   \n",
       "11         11            2                     5                    2   \n",
       "12        121           12                    52                    5   \n",
       "13         66           14                    13                    4   \n",
       "14        361           25                   178                   47   \n",
       "15        109           19                    38                   37   \n",
       "16        106            6                    58                   23   \n",
       "\n",
       "    Total Pred (oslopots)  Only stepanov right  Total Pred (stepanov)  \n",
       "0                      12                    0                     20  \n",
       "1                       0                    0                      0  \n",
       "2                     308                   30                    415  \n",
       "3                      45                    1                     52  \n",
       "4                       7                    0                      5  \n",
       "5                     420                   15                    310  \n",
       "6                      28                    2                     46  \n",
       "7                     108                    3                     72  \n",
       "8                       0                    0                      0  \n",
       "9                       0                    0                      0  \n",
       "10                     41                    1                     44  \n",
       "11                      5                    0                      6  \n",
       "12                     53                    2                     96  \n",
       "13                     16                    0                     20  \n",
       "14                    208                   14                    269  \n",
       "15                    109                    0                     11  \n",
       "16                     76                    6                     70  "
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sense_statistics(sense_comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "if sense in set_senses.difference(set(sense)):\n",
    "    print(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_senses.cop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'Comparison',\n",
       " u'Comparison.Concession',\n",
       " u'Comparison.Contrast',\n",
       " u'Contingency.Cause.Reason',\n",
       " u'Contingency.Cause.Result',\n",
       " u'Contingency.Condition',\n",
       " u'EntRel',\n",
       " u'Expansion',\n",
       " u'Expansion.Alternative',\n",
       " u'Expansion.Alternative.Chosen alternative',\n",
       " u'Expansion.Conjunction',\n",
       " u'Expansion.Instantiation',\n",
       " u'Expansion.Restatement',\n",
       " u'Temporal',\n",
       " u'Temporal.Asynchronous.Precedence'}"
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_senses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
